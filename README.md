# ADAPTIVE FREQUENCY TIME-DISTRIBUTION NETWORK (AFTNet) - A MULTISCALE DEBLURRING TECHNIQUE
# Abstract
Despite the significant progress achieved by image deblurring prevalent techniques, the great dilemma between computational efficiency enhancement and long-range degradation perturbationâ€™s elimination still persists, due to the large discrepancy between the degraded/sharp image pairs spectra. While some deep learning approaches adopt multi-scale algorithms to implement coarse-to-fine scheme which for deep semantics and low-scale RGB images feature fusion, imposes complex modules; others, seek solutions strictly in the frequency domain by utilizing transformation tools such as discrete Fourier/wavelet transform, which unfortunately is not optimally flexible to recover the most informative frequency component. To address this issue, we exhibit a novel image deblurring multi-scale adaptive frequency time-distribution paradigm based on single/multiple-inputs and multiple-outputs. Specifically, to efficiently handle frequency-specific blur patterns, we impose a content-adaptive and dual branch block which leverages a frequency-domain attention aggregated to spatial attention for dynamic features decomposition into multiple frequency bands. Moreover, to handle temporal consistency, we propose a module which computes optical flow between frames based on learned attention weights. Nonetheless, fine-grained feature adjustment is guaranteed as we offer an adaptive feature norm which provides dynamic feature normalization by feature calibration. In fine, our proposed AFTNet performs favourably against state-of-the-art algorithms on multiple real-world and synthetic deblurred datasets, both in terms of computational efficiency as well as objective and subjective quality.
